{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!gdown --fuzzy https://drive.google.com/file/d/1tM16OAlYUrimMpHsSs7GB1QN6swYuvCx/view?usp=sharing"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "19KCsMXY8RWa",
        "outputId": "d64332f4-bf39-4684-eaed-3eadbc2c7dbe"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1tM16OAlYUrimMpHsSs7GB1QN6swYuvCx\n",
            "From (redirected): https://drive.google.com/uc?id=1tM16OAlYUrimMpHsSs7GB1QN6swYuvCx&confirm=t&uuid=796ed1a8-1aae-42b9-a341-4a2d07443f32\n",
            "To: /content/histopathologic-cancer-detection.zip\n",
            "100% 6.77G/6.77G [01:09<00:00, 97.2MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/histopathologic-cancer-detection.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EO9uHd12CuIv",
        "outputId": "f76b4c62-2bbe-47f4-d2f6-7b985d160e93"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/histopathologic-cancer-detection.zip\n",
            "replace sample_submission.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pcam_directory = '/content/'"
      ],
      "metadata": {
        "id": "g_xX6dcoLcRX"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(torch.cuda.is_available())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4-TvaPVjPiv_",
        "outputId": "a75f79e7-861d-42ef-9691-a76e9ca25c6f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "from PIL import Image, ImageFilter\n",
        "import tifffile as tiff\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.nn import functional as F\n",
        "import torch.utils.model_zoo as model_zoo\n",
        "from torchvision import transforms\n",
        "from tqdm.notebook import tqdm\n",
        "import logging as log\n",
        "import IProgress"
      ],
      "metadata": {
        "id": "Gs50ialFcQC2"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_mapping = {}\n",
        "with open(os.path.join(pcam_directory, 'train_labels.csv'), 'r') as f:\n",
        "    reader = csv.reader(f)\n",
        "    next(reader)  # To skip the header\n",
        "    label_mapping = {slide_id: int(label) for [slide_id, label] in reader}"
      ],
      "metadata": {
        "id": "5sFhf5VZcbEy"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_fps = [fp for fp in os.listdir(os.path.join(pcam_directory, 'train'))]\n",
        "for fp in all_fps: assert fp[-4:] == '.tif', fp[-4:]"
      ],
      "metadata": {
        "id": "O2E_xb-Cces7"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import random\n",
        "\n",
        "class PCamDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, examples, transform=None):\n",
        "        self.examples = examples\n",
        "        self.transform = transform\n",
        "        self.crop = 125\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        image_fp, label = self.examples[index]\n",
        "        image = Image.open(image_fp)\n",
        "        if self.transform is not None:\n",
        "            image = self.transform(image)\n",
        "        return image, torch.Tensor([label]).long()\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.examples)\n",
        "\n",
        "    def crop_image(self, image_data):\n",
        "        w, h = image_data.shape[1], image_data.shape[0]\n",
        "        startx = w // 2 - self.crop // 2\n",
        "        starty = h // 2 - self.crop // 2\n",
        "        return image_data[starty:starty + self.crop, startx:startx + self.crop]\n",
        "\n",
        "    def update_exclusion_list(self, exclude_indices):\n",
        "        \"\"\" Update the list of indices to exclude from the dataset. \"\"\"\n",
        "        self.exclude_indices = set(exclude_indices)\n",
        "\n",
        "    def degrade_all_images(self):\n",
        "      degraded_images = []\n",
        "      for image_fp, label in self.examples:\n",
        "          image = Image.open(image_fp)\n",
        "          if self.transform is not None:\n",
        "              image = self.transform(image)\n",
        "          degraded_image = self.degrade_image(image)\n",
        "          degraded_images.append(degraded_image)\n",
        "      return degraded_images\n",
        "\n",
        "    def create_gaussian_kernel(self, size, sigma):\n",
        "        \"\"\"Creates a Gaussian kernel only if not already cached.\"\"\"\n",
        "        if (size, sigma) not in self.kernel_cache:\n",
        "            ax = torch.linspace(-(size - 1) / 2., (size - 1) / 2., size)\n",
        "            xx, yy = torch.meshgrid(ax, ax)\n",
        "            kernel = torch.exp(-(xx**2 + yy**2) / (2 * sigma**2))\n",
        "            kernel = kernel / torch.sum(kernel)\n",
        "            self.kernel_cache[(size, sigma)] = kernel.view(1, 1, size, size)\n",
        "        return self.kernel_cache[(size, sigma)]\n",
        "\n",
        "    def degrade_image(self, image):\n",
        "        c, h, w = image.shape\n",
        "        patch_size = random.randint(10, 32)\n",
        "        x = random.randint(0, w - patch_size)\n",
        "        y = random.randint(0, h - patch_size)\n",
        "\n",
        "        # Operate directly on a slice of the original image\n",
        "        patch = image[:, y:y + patch_size, x:x + patch_size]\n",
        "\n",
        "        # Apply Gaussian blur to the patch\n",
        "        if random.random() > 0.5:\n",
        "            size = random.choice([3, 5, 7])  # Kernel size\n",
        "            sigma = random.uniform(0.5, 1.5)  # Sigma for Gaussian kernel\n",
        "            blur_kernel = self.create_gaussian_kernel(size, sigma).repeat(c, 1, 1, 1).to(image.device)\n",
        "            patch = F.pad(patch, (size//2, size//2, size//2, size//2), mode='reflect')\n",
        "            patch = F.conv2d(patch.unsqueeze(0), blur_kernel, padding=0, stride=1, groups=c).squeeze(0)\n",
        "\n",
        "        # Add Gaussian noise\n",
        "        if random.random() > 0.5:\n",
        "            noise = torch.randn_like(patch) * 0.05\n",
        "            patch.add_(noise)  # In-place addition of noise\n",
        "\n",
        "        # No need to place back, patch is a reference to a slice of 'image'\n",
        "        return image\n",
        "\n",
        "def show_dataset_images(dataset, indices, ncols=3):\n",
        "    plt.figure(figsize=(15, 5))  # Adjust the size as needed\n",
        "    for i, idx in enumerate(indices):\n",
        "        image, _ = dataset[idx]\n",
        "        if isinstance(image, torch.Tensor):  # Check if the image needs to be converted from a tensor\n",
        "            image = image.permute(1, 2, 0).numpy()  # Adjust dimensions for Matplotlib\n",
        "        plt.subplot(1, ncols, i + 1)\n",
        "        plt.imshow(image)\n",
        "        plt.title(f\"Index: {idx}\")\n",
        "        plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "permutation = np.random.permutation(range(len(all_fps)))\n",
        "dataset = PCamDataset([\n",
        "        (os.path.join(pcam_directory, 'train', all_fps[index]), label_mapping[all_fps[index][:-4]])\n",
        "        for index in permutation[:int(len(permutation) * .8)]\n",
        "    ], transform= transforms.Compose([\n",
        "    transforms.ColorJitter(),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomVerticalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])  # Imagenet statistics\n",
        "]))\n",
        "dataloader = DataLoader(dataset, batch_size=32, shuffle=True),\n",
        "degraded_images = dataset.degrade_all_images()\n",
        "show_dataset_images(degraded_images, range(12), ncols=3)\n"
      ],
      "metadata": {
        "id": "5JBJgMk336F8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#code below based off of slideflow implementation of DeepFocus algorithm (https://github.com/jamesdolezal/slideflow/blob/master/slideflow/slide/qc/deepfocus.py)\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class DeepFocusV3(nn.Module):\n",
        "    def __init__(self, filters=(32, 32, 64, 128, 128), kernel_sizes=(5, 3, 3, 3, 3), fc=(128, 64)):\n",
        "        super(DeepFocusV3, self).__init__()\n",
        "        self.filters = filters\n",
        "        self.kernel_sizes = kernel_sizes\n",
        "\n",
        "        # Assuming the input images are 64x64 RGB images\n",
        "        # Convolutional layers\n",
        "        self.conv1 = nn.Conv2d(3, filters[0], kernel_size=kernel_sizes[0], padding='same')\n",
        "        self.bn1 = nn.BatchNorm2d(filters[0])\n",
        "\n",
        "        self.conv2 = nn.Conv2d(filters[0], filters[1], kernel_size=kernel_sizes[1], padding='same')\n",
        "        self.bn2 = nn.BatchNorm2d(filters[1])\n",
        "\n",
        "        self.conv3 = nn.Conv2d(filters[1], filters[2], kernel_size=kernel_sizes[2], padding='same')\n",
        "        self.bn3 = nn.BatchNorm2d(filters[2])\n",
        "        self.pool1 = nn.MaxPool2d(2, padding='same')\n",
        "\n",
        "        self.conv4 = nn.Conv2d(filters[2], filters[3], kernel_size=kernel_sizes[3], padding='same')\n",
        "        self.bn4 = nn.BatchNorm2d(filters[3])\n",
        "        self.pool2 = nn.MaxPool2d(2, padding='same')\n",
        "\n",
        "        self.conv5 = nn.Conv2d(filters[3], filters[4], kernel_size=kernel_sizes[4], padding='same')\n",
        "        self.bn5 = nn.BatchNorm2d(filters[4])\n",
        "        self.pool3 = nn.MaxPool2d(2, padding='same')\n",
        "\n",
        "        # Fully connected layers\n",
        "        self.fc1 = nn.Linear(filters[4] * 8 * 8, fc[0])  # Adjust the sizing calculation as necessary\n",
        "        self.bn6 = nn.BatchNorm1d(fc[0])\n",
        "        self.dropout1 = nn.Dropout(0.2)\n",
        "\n",
        "        self.fc2 = nn.Linear(fc[0], fc[1])\n",
        "        self.bn7 = nn.BatchNorm1d(fc[1])\n",
        "        self.dropout2 = nn.Dropout(0.2)\n",
        "\n",
        "        self.fc3 = nn.Linear(fc[1], 2)  # Output layer for binary classification\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Subtract mean\n",
        "        x = x - torch.mean(x, dim=(2, 3), keepdim=True)\n",
        "\n",
        "        # Convolutional blocks\n",
        "        x = F.relu(self.bn1(self.conv1(x)))\n",
        "        x = F.relu(self.bn2(self.conv2(x)))\n",
        "        x = F.relu(self.bn3(self.conv3(x)))\n",
        "        x = self.pool1(x)\n",
        "\n",
        "        x = F.relu(self.bn4(self.conv4(x)))\n",
        "        x = self.pool2(x)\n",
        "\n",
        "        x = F.relu(self.bn5(self.conv5(x)))\n",
        "        x = self.pool3(x)\n",
        "\n",
        "        # Flatten the output for the fully connected layers\n",
        "        x = torch.flatten(x, 1)\n",
        "\n",
        "        # Fully connected layers\n",
        "        x = F.relu(self.bn6(self.fc1(x)))\n",
        "        x = self.dropout1(x)\n",
        "\n",
        "        x = F.relu(self.bn7(self.fc2(x)))\n",
        "        x = self.dropout2(x)\n",
        "\n",
        "        x = F.softmax(self.fc3(x), dim=1)\n",
        "        return x\n",
        "\n",
        "# Instantiate the model and transfer it to the device\n",
        "model = DeepFocusV3()\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "model.eval()  # Set the model to evaluation mode\n",
        "\n",
        "# Function to predict clarity\n",
        "exclude_indices = []\n",
        "def predict_clarity(dataloader, model, threshold = 0.75):\n",
        "    with torch.no_grad():  # No need to track gradients\n",
        "        for i, (images, labels) in enumerate(dataloader):\n",
        "            images = images.to(device)\n",
        "            outputs = model(images)\n",
        "            probabilities = torch.nn.functional.softmax(outputs, dim=1)\n",
        "            clear_probs = probabilities[:, 1]  # Index 1 for 'clear'\n",
        "\n",
        "            # Decide which images to exclude based on the threshold\n",
        "            for j, prob in enumerate(clear_probs):\n",
        "                if prob.item() < threshold:  # Less than 75% probability of being 'clear'\n",
        "                    exclude_indices.append(i * dataloader.batch_size + j)\n",
        "    dataset.update_exclusion_list(set(exclude_indices))\n",
        "\n",
        "# Predict clarity of PCAM images\n",
        "predict_clarity(dataloader, model)\n"
      ],
      "metadata": {
        "id": "XdsqZzHZja70"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}